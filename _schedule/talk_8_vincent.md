---
sequence_id: 10
speaker: Vincent Sitzmann
# webpage: https://jane.doe
# affil: Buzz University
# affil_link: https://buzz.edu
img: vincent.jpg
# affil2: BuzzFizz Corp
# affil2_link: https://buzzfizz.corp
title: Light Field Networks - Neural Scene Representation with Single-Evaluation Rendering
time: 1545
abstract: Given only a single picture, people are capable of inferring a mental representation that encodes rich information about the underlying 3D scene. We acquire this skill not through massive labeled datasets of 3D scenes, but through self-supervised observation and interaction. Building machines that can infer similarly rich neural scene representations is critical if they are to one day parallel peopleâ€™s ability to understand, navigate, and interact with their surroundings. Recent progress on 3D-structured neural scene representations suggests a path towards self-supervised learning of such representations. However, current approaches rely on volumetric rendering or sphere-tracing, which incurs dramatic costs that scale with the complexity and depth range of the scene. I will discuss our recent work, Light Field Networks, that strikes a different trade-off of strictly enforcing multi-view consistency and computational complexity, offering a path towards scalable self-supervised scene representation learning.
---
